# -*- coding: utf-8 -*-
"""
Created on Mon Oct  1 22:15:54 2023
@author: Dongyuan Ge
"""
import numpy as np
import math
import random
import string
import matplotlib as mpl
import matplotlib.pyplot as plt



# 设置随机数种子（可选，但有助于结果的可重复性）
np.random.seed(0)  # 设置种子为0，以便每次运行代码时都能得到相同的结果

# 生成区间[a,b]内的随机数
def random_number(a, b):
    return (b - a) * random.random() + a


# 生成一个矩阵，大小为m*n,并且设置默认零矩阵
def makematrix(m, n, fill=0.0):
    a = []
    for i in range(m):
        a.append([fill] * n)
    return a


# 函数sigmoid(),这里采用tanh，因为看起来要比标准的sigmoid函数好看
def sigmoid(x):
    return 1*(math.tanh(x))


# 函数sigmoid的派生函数
def derived_sigmoid(x):
    return 1*(1.0 - x ** 2)


# 构造三层BP网络架构
class BPNN:
    def __init__(self, num_in, num_hidden, num_out):
        # 输入层，隐藏层，输出层的节点数
        self.num_in = num_in   # 增加一个偏置结点
        self.num_hidden = num_hidden   # 增加一个偏置结点
        self.num_out = num_out

        # 激活神经网络的所有节点（向量）
        self.active_in = [1.0] * self.num_in
        self.active_hidden = [1.0] * self.num_hidden
        self.active_out = [1.0] * self.num_out   #可以用2

        # 创建权重矩阵
        self.wight_in = makematrix(self.num_in, self.num_hidden)
        self.wight_out = makematrix(self.num_hidden, self.num_out)

        #对权值矩阵赋初值
        for i in range(self.num_in):
            for j in range(self.num_hidden):
                self.wight_in[i][j] = random_number(-0.9, 0.9)   #原来的是random_number(-0.2, 0.2)
        for j in range(self.num_hidden):
            for k in range(self.num_out):
                self.wight_out[j][k] = random_number(-0.9, 0.9)

        self.wight_in=[

           #
            [5.437694944452474, -7.806223283283583, 3.4010231484516193, 0.034119074785716776, 1.2228116168128274,  -0.30933986987046547,  4.904352121016822, -7.414289798059994, 3.1015855611738656, -0.04710478970670941, 0.5735930261628404, 0.3596677834410535],
            [0.12740669054821877, -5.014850113538859, -0.8477613831748844, 1.0170493195084434, -3.9092428052281813, -0.8337627663998691 ,  0.11600005201293703, -4.383986083039213, -0.878548675564849, 0.5426955763115496, -3.0077358823464193, -1.008895067560161],
            [- 0.0911658657340839, 4.287049084075241, -26.025559495688388, 15.61574137245841, 9.910987445701943,    6.332991843877077,    -0.350967249617043, 4.693163452197321, -25.57072835210723, 15.64010607988969, 9.09444403376687, 6.504187149219303],
            [-0.3329881770198686, 0.5570343535578456, -1.891982037571118, -0.4828169874986403, -0.9438029484839108,   -0.26154659350860215,  -0.3312100312908608, 0.5586069476235483, -1.8900185930455378, -0.4787734956038044, -0.9491890356647626, -0.2583882796923472]
        ]
        self.wight_out = [
            # 以下为左摄像机的
            [1.4796827479033727, 1.7741334632632455,   0,  0],
            [0.5854511070940049, 0.6058183553069706,   0, 0],
            [2.289149627931907, -0.0079517354652275,   0, 0],
            [3.9661153628492634, 0.5987316896140886,   0, 0],
            [0.35411880211121516, -4.04911374454641,   0, 0],
            [- 3.531453462241525, 4.493704320375342,  0, 0],
#以下为右摄像机的
            [0,  0,   1.526365001481235, 0.1720004723222518],
            [0,  0,   0.31461897044945647, 0.07770851147168532],
            [0,  0,   1.56842736593774, 0.14304530252314748],
            [0,  0,   2.784647056772489, 0.7507135312560574],
            [0,  0,   0.8140684942298372, -3.645050120033926],
            [0,  0,  - 3.30320976779897, 3.7892961857912]
            # 2024.10.05      前两次运行得到的权值的组合
        ]
        # 最后建立动量因子（矩阵）
        self.ci = makematrix(self.num_in, self.num_hidden)
        self.co = makematrix(self.num_hidden, self.num_out)

        # 信号正向传播

    def update(self, inputs):
        if len(inputs) != self.num_in:
            raise ValueError('与输入层节点数不符')

        # 数据输入输入层
        for i in range(self.num_in ):
                 self.active_in[i] = inputs[i]  # active_in[]是输入数据的矩阵

        # 数据在隐藏层的处理
        for j in range(self.num_hidden ):
            sum = 0.0
            for i in range(self.num_in):
                sum = sum + self.active_in[i] * self.wight_in[i][j]
            self.active_hidden[j] = sigmoid(sum)  # active_hidden[]是处理完输入数据之后存储，作为输出层的输入数据

        # 数据在输出层的处理
        for k in range(self.num_out):
            sum = 0.0
            for j in range(self.num_hidden):
                sum = sum + self.active_hidden[j] * self.wight_out[j][k]
            self.active_out[k] = sigmoid(sum)  # 与上同理

        return self.active_out[:]

    # 误差反向传播
    def errorbackpropagate(self, targets, lr, m):  # lr是学习率， m是动量因子
        if len(targets) != self.num_out:
            raise ValueError('与输出层节点数不符！')

        # 首先计算输出层的误差
        out_deltas = [0.0] * self.num_out
        for k in range(self.num_out):
            error = targets[k] - self.active_out[k]
            out_deltas[k] = derived_sigmoid(self.active_out[k]) * error

        # 然后计算隐藏层误差
        hidden_deltas = [0.0] * self.num_hidden
        for j in range(self.num_hidden):
            error = 0.0
            for k in range(self.num_out):
                error = error + out_deltas[k] * self.wight_out[j][k]
            hidden_deltas[j] = derived_sigmoid(self.active_hidden[j]) * error

        # 然后更新输入的信息
        for i in range(self.num_in-1):
            change=[0, 0, 0]
            for j in range(self.num_hidden):
                change[i] =change[i]+ hidden_deltas[j] * self.wight_in[i][j]

            self.active_in[i] = self.active_in[i] + lr * change[i]
                #self.ci[i][j] = change

        # 计算总误差
        error = 0.0
        for i in range(len(targets)):
            error = error + 0.5 * (targets[i] - self.active_out[i]) ** 2
        return error

    # 测试
    def test(self, patterns):
        for i in patterns:
            print(i[0], '->', self.update(i[0]))

    # 权重
    def weights(self):
        print("输入层权重")
        for i in range(self.num_in):
            print(self.wight_in[i])
        print("输出层权重")
        for i in range(self.num_hidden):
            print(self.wight_out[i])


    def train(self, pattern, itera=300001, lr=0.00200, m=0.00):

        #for j in pattern:
        for k, j in enumerate( pattern):
            for i in range(itera):  # 9500000
                error = 0.0
                if i == 0:
                   inputs = j[0]
                #   print('initial1=',inputs)
                   # inputs=[0.9698416053274535, 0.9492286353372284, 0.7490594680050898, 0.0001]
                   # print('initial2=', inputs)
                   targets = j[1]
                   self.update(inputs)
                   error = error + self.errorbackpropagate(targets, lr, m)
                else:
            # for j in pattern:
                   inputs =[self.active_in[0],self.active_in[1],self.active_in[2],0.0001]
                   # print('gdy_1030=', inputs)
                   targets = j[1]
                   self.update(inputs)
                   error = error + self.errorbackpropagate(targets, lr, m)
                if i % 300000 == 0:
                   # print('误差gdy %-.25f'  error)
                   # print('gdy_inputs=', inputs)
                   # print(  error)
                   # print( inputs)
                   print(k+1,error, inputs)
                 #  print(inputs)

# 实例
def demo():
    gdy = np.random.uniform(0, 1, 3);
    gdy3=np.concatenate((np.random.uniform(0, 1, 3),[0.0001]),0)
    patt  =  [

         #np.concatenate(
         #gdy3=np.concatenate((np.random.uniform(0, 1, 3),[0.0001]),0)
        [gdy3,
         [0.044995767, 0.233700393, 0.012892205, 0.184324649]],
        [gdy3,
         [0.065722645, 0.231985544, 0.029807641, 0.183760876]],
        [gdy3,
         [0.086453548, 0.230236930, 0.046720379, 0.183230426]],
        [gdy3,
         [0.107206932, 0.228510490, 0.063604401, 0.182707887]],
        [gdy3,
         [0.127922632, 0.226790954, 0.080473571, 0.182188158]],
        [gdy3,
         [0.148621050, 0.225026893, 0.097295420, 0.181672730]],
        [gdy3,
         [0.169314019, 0.223260278, 0.114058760, 0.181161780]],
        [gdy3,
         [0.046433568, 0.254545430, 0.013385019, 0.201128160]],
        [gdy3,
         [0.067184367, 0.252791930, 0.030299855, 0.200547739]],
        [gdy3,
         [0.087985928, 0.251029676, 0.047218257, 0.199995798]],
        [gdy3,
         [0.108800950, 0.249280715, 0.064119649, 0.199447175]],
        [gdy3,
         [0.129615600, 0.247515082, 0.081003787, 0.198913059]],
        [gdy3,
         [0.150365231, 0.245755440, 0.097837799, 0.198378724]],
        [gdy3,
         [0.171129882, 0.244021059, 0.114623486, 0.197844550]],
        [gdy3,
         [0.047879522, 0.275523325, 0.013861055, 0.217979503]],
        [gdy3,
         [0.068677725, 0.273757855, 0.030794775, 0.217394670]],
        [gdy3,
         [0.089562879, 0.271988523, 0.047714215, 0.216808824]],
        [gdy3,
         [0.110423072, 0.270209068, 0.064639113, 0.216241619]],
        [gdy3,
         [0.131265805, 0.268473624, 0.081529128, 0.215681774]],
        [gdy3,
         [0.152151267, 0.266689022, 0.098381724, 0.215129597]],
        [gdy3,
         [0.172972126, 0.264938690, 0.115188043, 0.214585379]],
        [gdy3,
         [0.049315139, 0.296628868, 0.014321095, 0.234866342]],
        [gdy3,
         [0.070182490, 0.294837639, 0.031272071, 0.234258475]],
        [gdy3,
         [0.091123424, 0.293067725, 0.048213990, 0.233654500]],
        [gdy3,
         [0.112065963, 0.291303375, 0.065145600, 0.233076055]],
        [gdy3,
         [0.132984782, 0.289546924, 0.082052373, 0.232498879]],
        [gdy3,
         [0.153933245, 0.287781527, 0.098925230, 0.231929695]],
        [gdy3,
         [0.174878634, 0.286038339, 0.115753765, 0.231361356]],
        [gdy3,
         [0.050773484, 0.317775419, 0.014793986, 0.251774277]],
        [gdy3,
         [0.071697382, 0.315990380, 0.031745379, 0.251144644]],
        [gdy3,
         [0.092682231, 0.314236961, 0.048700496, 0.250543385]],
        [gdy3,
         [0.113703534, 0.312480515, 0.065648355, 0.249941747]],
        [gdy3,
         [0.134740521, 0.310717262, 0.082574960, 0.249348134]],
        [gdy3,
         [0.155767168, 0.308981668, 0.099469698, 0.248762814]],
        [gdy3,
         [0.176817268, 0.307276974, 0.116317384, 0.248177115]],
        [gdy3,
         [0.052242940, 0.339005414, 0.015246906, 0.268706086]],
        [gdy3,
         [0.073247485, 0.337234658, 0.032210716, 0.268080801]],
        [gdy3,
         [0.094298609, 0.335432169, 0.049183013, 0.267435926]],
        [gdy3,
         [0.115397255, 0.333688641, 0.066150220, 0.266823292]],
        [gdy3,
         [0.136506774, 0.331960929, 0.083101784, 0.266209987]],
        [gdy3,
         [0.157635486, 0.330264316, 0.100016497, 0.265626661]],
        [gdy3,
         [0.178764382, 0.328560080, 0.116890325, 0.265028298]],
        [gdy3,
         [0.053738240, 0.360194981, 0.015693271, 0.285617629]],
        [gdy3,
         [0.074802195, 0.358435348, 0.032670069, 0.284948268]],
        [gdy3,
         [0.095946402, 0.356696459, 0.049664424, 0.284304578]],
        [gdy3,
         [0.117127859, 0.354974021, 0.066652666, 0.283673593]],
        [gdy3,
         [0.138340043, 0.353300307, 0.083627283, 0.283069031]],
        [gdy3,
         [0.159531549, 0.351620062, 0.100562200, 0.282467358]],
        [gdy3,
         [0.180754489, 0.349934246, 0.117481077, 0.281878935]],
        [gdy3,
         [0.052420053, 0.234955867, 0.014192806, 0.182420877]],
        [gdy3,
         [0.071629248, 0.233709187, 0.030337537, 0.181899311]],
        [gdy3,
         [0.090821271, 0.232448319, 0.046452624, 0.181388028]],
        [gdy3,
         [0.110005976, 0.231164586, 0.062535524, 0.180880647]],
        [gdy3,
         [0.129156942, 0.229854580, 0.078577120, 0.180385489]],
        [gdy3,
         [0.148328421, 0.228535553, 0.094568412, 0.179897674]],
        [gdy3,
         [0.167411159, 0.227191766, 0.110492845, 0.179417698]],
        [gdy3,
         [0.053445012, 0.254287744, 0.014676418, 0.198443266]],
        [gdy3,
         [0.072687333, 0.252997872, 0.030810500, 0.197898056]],
        [gdy3,
         [0.091944412, 0.251682239, 0.046935478, 0.197359459]],
        [gdy3,
         [0.111191779, 0.250348622, 0.063035706, 0.196836189]],
        [gdy3,
         [0.130445194, 0.249006225, 0.079088953, 0.196315374]],
        [gdy3,
         [0.149611883, 0.247676663, 0.095098604, 0.195807341]],
        [gdy3,
         [0.168777861, 0.246322877, 0.111043446, 0.195311379]],
        [gdy3,
         [0.054465276, 0.273802736, 0.015129608, 0.214507968]],
        [gdy3,
         [0.073761107, 0.272467660, 0.031287208, 0.213966932]],
        [gdy3,
         [0.093080063, 0.271120468, 0.047411954, 0.213409740]],
        [gdy3,
         [0.112394561, 0.269772268, 0.063519074, 0.212863414]],
        [gdy3,
         [0.131698888, 0.268415114, 0.079591520, 0.212322506]],
        [gdy3,
         [0.150956098, 0.267058513, 0.095622907, 0.211795484]],
        [gdy3,
         [0.170258353, 0.265699370, 0.111582044, 0.211277330]],
        [gdy3,
         [0.055466455, 0.293480335, 0.015577098, 0.230630279]],
        [gdy3,
         [0.074841096, 0.292095374, 0.031740995, 0.230064797]],
        [gdy3,
         [0.094222632, 0.290732683, 0.047887917, 0.229510493]],
        [gdy3,
         [0.113613670, 0.289359198, 0.064001087, 0.228941604]],
        [gdy3,
         [0.132996889, 0.287993912, 0.080089872, 0.228389356]],
        [gdy3,
         [0.152347973, 0.286630522, 0.096137419, 0.227844856]],
        [gdy3,
         [0.171705737, 0.285260755, 0.112136519, 0.227308456]],
        [gdy3,
         [0.056494161, 0.313282941, 0.016008657, 0.246824622]],
        [gdy3,
         [0.075928219, 0.311882394, 0.032184120, 0.246226419]],
        [gdy3,
         [0.095384835, 0.310491574, 0.048345307, 0.245632377]],
        [gdy3,
         [0.114848982, 0.309123442, 0.064475464, 0.245057191]],
        [gdy3,
         [0.134325909, 0.307736909, 0.080583743, 0.244488885]],
        [gdy3,
         [0.153777089, 0.306371403, 0.096649769, 0.243933134]],
        [gdy3,
         [0.173205778, 0.305009356, 0.112677368, 0.243374075]],
        [gdy3,
         [0.057519495, 0.333151503, 0.016429206, 0.263039625]],
        [gdy3,
         [0.077032397, 0.331728906, 0.032618187, 0.262420032]],
        [gdy3,
         [0.096544009, 0.330332020, 0.048795628, 0.261806519]],
        [gdy3,
         [0.116099068, 0.328978673, 0.064943660, 0.261201574]],
        [gdy3,
         [0.135654899, 0.327582856, 0.081074523, 0.260614051]],
        [gdy3,
         [0.155163791, 0.326262297, 0.097163973, 0.260036600]],
        [gdy3,
         [0.174692476, 0.324904196, 0.113212432, 0.259470834]],
        [gdy3,
         [0.058588110, 0.353147206, 0.016840371, 0.279286510]],
        [gdy3,
         [0.078154827, 0.351698978, 0.033044795, 0.278635055]],
        [gdy3,
         [0.097759778, 0.350291698, 0.049230745, 0.278007203]],
        [gdy3,
         [0.117380379, 0.348927561, 0.065409784, 0.277392235]],
        [gdy3,
         [0.137023682, 0.347562215, 0.081560175, 0.276791031]],
        [gdy3,
         [0.156641933, 0.346212034, 0.097681311, 0.276198680]],
        [gdy3,
         [0.176273548, 0.344915862, 0.113753444, 0.275620463]],
        [gdy3,
         [0.059383290, 0.238124162, 0.014688374, 0.180920309]],
        [gdy3,
         [0.077287878, 0.237372209, 0.030192875, 0.180456085]],
        [gdy3,
         [0.095201602, 0.236602042, 0.045636951, 0.179996261]],
        [gdy3,
         [0.113077028, 0.235807727, 0.061053290, 0.179541487]],
        [gdy3,
         [0.130913081, 0.234991307, 0.076425312, 0.179089165]],
        [gdy3,
         [0.148706582, 0.234136055, 0.091734273, 0.178649635]],
        [gdy3,
         [0.166457159, 0.233259748, 0.106973015, 0.178225603]],
        [gdy3,
         [0.059974848, 0.255865557, 0.015132989, 0.196107793]],
        [gdy3,
         [0.077935548, 0.255060702, 0.030638796, 0.195617058]],
        [gdy3,
         [0.095887754, 0.254232824, 0.046076163, 0.195132602]],
        [gdy3,
         [0.113833491, 0.253382871, 0.061509273, 0.194654689]],
        [gdy3,
         [0.131750495, 0.252525995, 0.076901350, 0.194190161]],
        [gdy3,
         [0.149601961, 0.251621339, 0.092225986, 0.193720631]],
        [gdy3,
         [0.167412536, 0.250711600, 0.107482428, 0.193268567]],
        [gdy3,
         [0.060541271, 0.273843102, 0.015549312, 0.211425554]],
        [gdy3,
         [0.078581102, 0.272978224, 0.031057079, 0.210916758]],
        [gdy3,
         [0.096592216, 0.272096684, 0.046510707, 0.210412115]],
        [gdy3,
         [0.114587729, 0.271206688, 0.061958650, 0.209912001]],
        [gdy3,
         [0.132578221, 0.270299575, 0.077361186, 0.209416786]],
        [gdy3,
         [0.150513251, 0.269373040, 0.092709190, 0.208926826]],
        [gdy3,
         [0.168427260, 0.268438981, 0.107985743, 0.208433523]],
        [gdy3,
         [0.061159573, 0.292069754, 0.015953841, 0.226791277]],
        [gdy3,
         [0.079248803, 0.291109622, 0.031472226, 0.226268879]],
        [gdy3,
         [0.097333273, 0.290181219, 0.046941131, 0.225725508]],
        [gdy3,
         [0.115409804, 0.289251298, 0.062398661, 0.225204058]],
        [gdy3,
         [0.133430558, 0.288311926, 0.077812462, 0.224689536]],
        [gdy3,
         [0.151457156, 0.287365906, 0.093175084, 0.224182416]],
        [gdy3,
         [0.169439929, 0.286417377, 0.108484090, 0.223691510]],
        [gdy3,
         [0.061724639, 0.310387460, 0.016344284, 0.242210553]],
        [gdy3,
         [0.079896740, 0.309421449, 0.031877730, 0.241668640]],
        [gdy3,
         [0.098031486, 0.308471080, 0.047370938, 0.241107079]],
        [gdy3,
         [0.116162612, 0.307519208, 0.062820345, 0.240571985]],
        [gdy3,
         [0.134300375, 0.306554516, 0.078260103, 0.240038293]],
        [gdy3,
         [0.152418045, 0.305570997, 0.093642872, 0.239506375]],
        [gdy3,
         [0.170524065, 0.304605163, 0.108964721, 0.239002718]],
        [gdy3,
         [0.062309101, 0.328900018, 0.016714760, 0.257669630]],
        [gdy3,
         [0.080549425, 0.327916539, 0.032260890, 0.257108469]],
        [gdy3,
         [0.098759879, 0.326920196, 0.047790343, 0.256552697]],
        [gdy3,
         [0.116992719, 0.325920190, 0.063264246, 0.255998284]],
        [gdy3,
         [0.135197361, 0.324936300, 0.078698711, 0.255445057]],
        [gdy3,
         [0.153444292, 0.323968506, 0.094100248, 0.254900172]],
        [gdy3,
         [0.171598386, 0.322998661, 0.109465045, 0.254364011]],
        [gdy3,
         [0.062900286, 0.347531355, 0.017073585, 0.273188854]],
        [gdy3,
         [0.081201668, 0.346502470, 0.032632491, 0.272588678]],
        [gdy3,
         [0.099503353, 0.345494047, 0.048172897, 0.272015519]],
        [gdy3,
         [0.117843401, 0.344491445, 0.063694762, 0.271441831]],
        [gdy3,
         [0.136161953, 0.343501729, 0.079156512, 0.270874601]],
        [gdy3,
         [0.154456003, 0.342543872, 0.094580874, 0.270314111]],
        [gdy3,
         [0.172735170, 0.341553079, 0.109960373, 0.269760623]],

    ]

    # 创建神经网络，4个输入节点，12个隐藏层节点，4个输出层节点
    n = BPNN(4, 12, 4)
    # 训练神经网络
    n.train(patt)
    # 测试神经网络
    # n.test(patt)
    # 查阅权重值
    n.weights()


if __name__ == '__main__':
    demo()